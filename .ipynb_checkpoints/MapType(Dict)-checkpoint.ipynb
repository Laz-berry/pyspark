{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7728fb7c-9327-4c95-8ac1-54c3db423856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b3d34cf-f69a-4a75-bba7-16ee5eafaf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, MapType\n",
    "mapCol = MapType(StringType(),StringType(),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59fe598d-0c46-494d-bc4a-28025a5bcc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. 첫 번째 매개변수는 keyType맵에서 키 유형을 지정하는 데 사용됩니다.\\n2. 두 번째 매개변수는 valueType맵에서 값의 유형을 지정하는 데 사용됩니다.\\n3. 세 번째 매개변수는 valueContainsNull두 번째 매개변수의 값이 값을 수락할 수 있는지 \\n지정하는 데 사용되는 선택적 부울 유형입니다 Null/None.\\n4. 지도의 키는 None/Null값을 허용하지 않습니다.\\n5. PySpark는 작업할 여러 SQL 함수를 제공합니다 MapType.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. 첫 번째 매개변수는 keyType맵에서 키 유형을 지정하는 데 사용됩니다.\n",
    "2. 두 번째 매개변수는 valueType맵에서 값의 유형을 지정하는 데 사용됩니다.\n",
    "3. 세 번째 매개변수는 valueContainsNull두 번째 매개변수의 값이 값을 수락할 수 있는지 \n",
    "지정하는 데 사용되는 선택적 부울 유형입니다 Null/None.\n",
    "4. 지도의 키는 None/Null값을 허용하지 않습니다.\n",
    "5. PySpark는 작업할 여러 SQL 함수를 제공합니다 MapType.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6d43525-9baa-4bfd-bb34-bc8c336e7ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, MapType\n",
    "schema = StructType([\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('properties', MapType(StringType(),StringType()),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e413b4d3-cfa6-4008-a6c1-23af66f5a707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "+----------+-----------------------------+\n",
      "|name      |properties                   |\n",
      "+----------+-----------------------------+\n",
      "|James     |{eye -> brown, hair -> black}|\n",
      "|Michael   |{eye -> null, hair -> brown} |\n",
      "|Robert    |{eye -> black, hair -> red}  |\n",
      "|Washington|{eye -> grey, hair -> grey}  |\n",
      "|Jefferson |{eye -> , hair -> brown}     |\n",
      "+----------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "dataDictionary = [\n",
    "        ('James',{'hair':'black','eye':'brown'}),\n",
    "        ('Michael',{'hair':'brown','eye':None}),\n",
    "        ('Robert',{'hair':'red','eye':'black'}),\n",
    "        ('Washington',{'hair':'grey','eye':'grey'}),\n",
    "        ('Jefferson',{'hair':'brown','eye':''})\n",
    "        ]\n",
    "df = spark.createDataFrame(data=dataDictionary, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd420324-f16f-4db7-8646-ede7828903e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- hair: string (nullable = true)\n",
      " |-- eye: string (nullable = true)\n",
      "\n",
      "+----------+-----+-----+\n",
      "|      name| hair|  eye|\n",
      "+----------+-----+-----+\n",
      "|     James|black|brown|\n",
      "|   Michael|brown| null|\n",
      "|    Robert|  red|black|\n",
      "|Washington| grey| grey|\n",
      "| Jefferson|brown|     |\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3=df.rdd.map(lambda x: \\\n",
    "    (x.name,x.properties[\"hair\"],x.properties[\"eye\"])) \\\n",
    "    .toDF([\"name\",\"hair\",\"eye\"])\n",
    "df3.printSchema()\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f6ddfd2-4c1a-49ea-8dcc-cc6f2fb8144b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+\n",
      "|      name| hair|  eye|\n",
      "+----------+-----+-----+\n",
      "|     James|black|brown|\n",
      "|   Michael|brown| null|\n",
      "|    Robert|  red|black|\n",
      "|Washington| grey| grey|\n",
      "| Jefferson|brown|     |\n",
      "+----------+-----+-----+\n",
      "\n",
      "+----------+-----+-----+\n",
      "|      name| hair|  eye|\n",
      "+----------+-----+-----+\n",
      "|     James|black|brown|\n",
      "|   Michael|brown| null|\n",
      "|    Robert|  red|black|\n",
      "|Washington| grey| grey|\n",
      "| Jefferson|brown|     |\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using getItem\n",
    "df.withColumn(\"hair\",df.properties.getItem(\"hair\")) \\\n",
    "  .withColumn(\"eye\",df.properties.getItem(\"eye\")) \\\n",
    "  .drop(\"properties\") \\\n",
    "  .show()\n",
    "\n",
    "# Using properties\n",
    "df.withColumn(\"hair\",df.properties[\"hair\"]) \\\n",
    "  .withColumn(\"eye\",df.properties[\"eye\"]) \\\n",
    "  .drop(\"properties\") \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3160a04a-b64d-4993-80ac-a5e771800e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+\n",
      "|      name| key|value|\n",
      "+----------+----+-----+\n",
      "|     James| eye|brown|\n",
      "|     James|hair|black|\n",
      "|   Michael| eye| null|\n",
      "|   Michael|hair|brown|\n",
      "|    Robert| eye|black|\n",
      "|    Robert|hair|  red|\n",
      "|Washington| eye| grey|\n",
      "|Washington|hair| grey|\n",
      "| Jefferson| eye|     |\n",
      "| Jefferson|hair|brown|\n",
      "+----------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explode\n",
    "\n",
    "from pyspark.sql.functions import explode\n",
    "df.select(df.name,explode(df.properties)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e235c2f0-26da-4ed3-bbc4-f1ee71e77379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|      name|map_keys(properties)|\n",
      "+----------+--------------------+\n",
      "|     James|         [eye, hair]|\n",
      "|   Michael|         [eye, hair]|\n",
      "|    Robert|         [eye, hair]|\n",
      "|Washington|         [eye, hair]|\n",
      "| Jefferson|         [eye, hair]|\n",
      "+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# map_keys - take all map key\n",
    "# 경고 : 매우 느리게 실행\n",
    "\n",
    "from pyspark.sql.functions import map_keys\n",
    "df.select(df.name,map_keys(df.properties)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596506fb-b791-4230-b7a0-4d587d320dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_values() - take all map value\n",
    "\n",
    "from pyspark.sql.functions import map_values\n",
    "df.select(df.name,map_values(df.properties)).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
